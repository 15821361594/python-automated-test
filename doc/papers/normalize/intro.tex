\section{Introduction}

It has long been understood that effective automated testing often requires
test reduction \cite{DD,MinUnit,TCminim,ICSEDiff} to produce tests
without irrelevant operations\footnote{Bounded-exhaustive testing
  \cite{SoftBET} and some search-based approaches that
  optimize for short tests \cite{FA11} may not require reduction, but random
  testing \cite{RandFormal,HamletOnly}, model-checking
  \cite{Gastin04minimizationof}, and symbolic execution \cite{issta14}
  can all benefit.}.  In fact, test reduction is
now standard practice in industrial testing tools such as Mozilla's
{\tt jsfunfuzz} \cite{jsfunfuzz,jsfunfuzz2,lithium}.  However, simply reducing the length of a test
does not produce true semantic simplicity.  There may be many
(often far more than a thousand, in practice) 1-minimal\footnote{No
  single component of a 1-minimal/delta-debugged \cite{DD} test can be removed without
  causing the test to pass.} tests
that present different variations of a single fault.  Far too often,
reading more than one of these tests provides no useful
additional information on the cause of failure. 

Consider the three 1-minimal tests in Figure
\ref{threetests}.  These tests are very similar, and all result
in an unbalanced AVL tree (due to a missing call to {\tt rebalance} in
{\tt delete}).  However, the tests are syntactically different,
and a testing system that collects failing tests will present all
three of these tests to a user.  While there are methods for
attempting to determine which tests represent distinct faults
\cite{PLDI13}, the ideal solution is to go beyond mere test reduction
and convert all three of these
tests into a single, \emph{canonical} form that preserves failure
while deemphasizing accidental aspects of each test, such as
particular integer values and variable names, and ordering of steps.
%Unlike delta-debugging, this concept applies to test generation
%methods that produce 1-minimal tests.

Figure \ref{normalgen} shows the result of applying our \emph{test
  case normalization} algorithm to the three tests in Figure
\ref{threetests}, and then applying our \emph{test
  generalization} algorithm to the normalized test.  \emph{All
  three tests normalize to the same test}.  Normalization is
enabled by a term rewriting algorithm \cite{term2,term1} that operates
on the level of test actions, and is thus language-agnostic:
it works by successively rewriting tests into ``simpler''
versions that preserve failure and are likely to retain the
underlying cause of the failure. Many
different reduced tests therefore normalize to the same form.
Unlike delta-debugging, normalization applies even to 1-minimal test
cases.

The test also includes comments, produced by our
\emph{generalization} \cite{SmartCheck} algorithm, indicating what
about the test can be changed while preserving the property that
the test fails.  Generalization uses automated experiments to discover
a semantic neighborhood of tests that also fail.  For example,
the value 1 assigned to {\tt int0} in step 0 is not essential.  It
could be changed to any value in the range 5-20 without changing the
final result.  Similarly, the exact ordering of many steps in the test
case is inessential.  Finally, in step 9 ,instead of using the existing
value of {\tt int1} (4), a fresh assignment could be inserted before
the {\tt delete} call, setting {\tt int1} to 3 instead.  These
possible changes are not meant to be combined, but changing these aspects of the test one at a time
will preserve failure.  This annotation provides information allowing
a user to understand that a single test is representative of a
\emph{family} of failing tests.

Combining normalization and generalization avoids some common problems
with understanding automatically generated tests.  For instance,
when a large integer appears in such a test, the question always
arises --- is this unusual value important, or just a random number of
no significance \cite{MakeMost}?  After normalization, any large
values in a test are essential, rather than
accidental, because normalization includes value minimization.
Without the additional step of generalization it would be
easy to assume all small numeric values in normalized
tests are accidental.  Generalization informs a user when a small
value is required to reproduce a failure, and when it is simply an
artifact of normalization.

Normalization is not yet a complete solution to the problem of identifying
distinct faults (e.g., our algorithms do not apply to complex custom
test generators such as Csmith \cite{csmith} or {\tt jsfunfuzz}
\cite{jsfunfuzz}), but it is often highly effective.  Running 100,000
tests (of length 100) on the faulty AVL tree produces 860 failing test
cases with no duplicates.  Normalizing these reduces the number of
distinct failing tests to just 22.  Ideally \emph{all} failures
due to the same fault in the SUT (Software Under Test) would normalize
to a single, representative test.  We aim to
\emph{approximate} such a canonical form for faults.  Figure \ref{diffnorm},
in Section \ref{formalexample}, shows an AVL tree test that
normalizes differently.  The graph structure required for the {\tt
  delete} fault results in an
unusually poor effectiveness for normalization.  In experiments with 82 AVL tree faults,
the mean number of distinct failures after normalization for 1,000
tests was just 3.1 (with median 2). This fault, in contrast, produced 18
distinct failures.  Nonetheless, determining that the failure in Figure
\ref{diffnorm} (or one of the similarly structured other 20 failures)
is due to the same fault as the failure in Figure \ref{normalgen}
should be much less difficult than performing the same task over many hundreds of failures with much more extreme variation. 

The contributions of this paper are 1) normalization and
generalization for API-based tests, key steps towards a goal of
``one test to rule them all'' (per fault), 2) algorithms for
normalization and generalization that make use of the abstract
interface for testing provided by the TSTL \cite{tstl,NFM15,ISSTA15}
domain-specific language (DSL) \cite{Fow10}, and 3)
experimental results showing the value of normalization and
generalization.  Normalization preserves faults approximately
as well as delta-debugging, frequently provides additional test length
reduction for complex SUTs, and often reduces
the set of tests to be examined by more than an order of
magnitude. In many cases, the normalization is perfect (one test
per fault).  Normalization and generalization have also been useful in
understanding complicated tests for a variety of software
systems, including TSTL itself, the NumPy library for numeric
computation, and ArcPy, a widely-used, highly complex package for
Geographic Information System (GIS) automation.

\begin{figure}[t]
{\scriptsize
{\bf Test \#1}\hspace{0.415in} {\bf Test \#2} \hspace{0.41in}
{\bf Test \#3}
\begin{verbatim}
avl0 = avl.AVLTree()   int0 = 14              avl1 = avl.AVLTree()
int0 = 4               avl0 = avl.AVLTree()   int3 = 18 
int2 = 13              int2 = 13              avl1.insert(int3) 
int3 = 7               int1 = 15              int0 = 5 
avl0.insert(int2)      avl0.insert(int1)      int3 = 12 
avl0.insert(int3)      int1 = 11              avl1.insert(int0) 
int1 = 15              avl0.insert(int2)      int0 = 15 
avl0.insert(int1)      avl0.insert(int0)      avl1.insert(int0) 
avl0.insert(int0)      avl0.insert(int1)      avl1.insert(int3) 
avl0.delete(int2)      avl0.delete(int0)      int1 = 15 
                                              avl1.delete(int1) 
\end{verbatim}
}
%\vspace{-0.2in}
\caption {\scriptsize{Three random tests for one fault.}}
\label{threetests}
%\vspace{-0.15in}
\end{figure}

\begin{figure}[t]
{\scriptsize
\begin{code}
\textcolor{black!60}{\#[}
int0 = 1                              \textcolor{black!60}{\# STEP 0}
\textcolor{black!60}{\#  or int0 = 5 }
\textcolor{black!60}{\#   - int0 = 20} 
\textcolor{black!60}{\#  swaps with step 4}
int1 = 3                              \textcolor{black!60}{\# STEP 1}
\textcolor{black!60}{\#  or int1 = 5 }
\textcolor{black!60}{\#   - int1 = 20} 
\textcolor{black!60}{\#  swaps with step 6}
avl0 = avl.AVLTree()                  \textcolor{black!60}{\# STEP 2}
\textcolor{black!60}{\#] (steps in [] can be in any order)}
avl0.insert(int0)                     \textcolor{black!60}{\# STEP 3}
\textcolor{black!60}{\#[}
int0 = 2                              \textcolor{black!60}{\# STEP 4}
\textcolor{black!60}{\#  swaps with step 0}
avl0.insert(int1)                     \textcolor{black!60}{\# STEP 5}
\textcolor{black!60}{\#] (steps in [] can be in any order)}
int1 = 4                              \textcolor{black!60}{\# STEP 6}
\textcolor{black!60}{\#  or int1 = 5 }
\textcolor{black!60}{\#   - int1 = 20} 
\textcolor{black!60}{\#  swaps with step 1}
avl0.insert(int1)                     \textcolor{black!60}{\# STEP 7}
avl0.insert(int0)                     \textcolor{black!60}{\# STEP 8}
avl0.delete(int1)                     \textcolor{black!60}{\# STEP 9}
\textcolor{black!60}{\#  or (}
\textcolor{black!60}{\#      int1 = 3  ;}
\textcolor{black!60}{\#      avl0.delete(int1) }
\textcolor{black!60}{\#     )}
\end{code}
}
\caption{\scriptsize{Normalization and generalization for all three tests.
  Lines beginning with \# are comments in Python, used for annotations.}}
\label{normalgen}
\end{figure}

