\section{Introduction}

It has long been understood that effective automated testing often requires
test case reduction \cite{DD,MinUnit,TCminim,ICSEDiff} to produce test cases
without irrelevant operations\footnote{Bounded-exhaustive testing
  \cite{SoftBET} and some search-based approaches that
  optimize for short tests \cite{FA11} may not require reduction, but random
  testing \cite{RandFormal,HamletOnly}, model-checking
  \cite{Gastin04minimizationof}, and symbolic execution \cite{issta14}
  can all benefit.}.  In fact, test case reduction is
now standard practice in industrial testing tools such as Mozilla's
{\tt jsfunfuzz} \cite{jsfunfuzz,jsfunfuzz2,lithium}.  However, simply reducing the length of a test case
does not produce any kind of semantic simplicity.  There may be many
(often far more than a thousand, in practice) 1-minimal test cases
that present different variations of a single fault.  Far too often,
reading more than one of these test cases provides no useful
additional information on the cause of failure. 

Consider the three test cases shown in Figure \ref{threetests}.  These
test cases are obviously very similar, and all lead to a
violation of the property that an AVL tree must always be nearly
balanced (due to a missing call to {\tt rebalance} in {\tt delete}).  However, the test cases are
syntactically different, and a testing system that collects
failing test cases will present all three of these tests to a user.
While there are methods for attempting to determine which test cases
represent distinct faults \cite{PLDI13}, the ideal solution is
to convert all three of these test cases into a single,
\emph{canonical} form that preserves the structure of the failure while de-emphasizing
such accidental aspects of each test case as the particular integer
values and variables used, and the ordering of assignments and
insertions.  Unlike delta-debugging, this concept applies to 
test generation methods that produce short or even minimal tests.

Figure \ref{normalgen} shows the result of applying our \emph{test
  case normalization} algorithm to the three tests in Figure
\ref{threetests}, and then applying our \emph{test case
  generalization} algorithm to the normalized test case.  \emph{All
  three test cases normalize to the same test case}.  Our normalization is
enabled by a strongly normalizing term rewriting algorithm that operates
on the level of test actions, and is thus language-agnostic:
it works by successively rewriting test cases into ``simpler''
versions that preserve failure and are likely to retain the
underlying cause of the failure in the original test case. Many
different reduced test cases therefore normalize to the same form.

The test case also includes comments, produced by our
\emph{generalization} \cite{SmartCheck} algorithm, indicating what
about the test case can be changed while preserving the property that
the test fails.  Generalization uses automated experiments to discover
a semantic neighborhood of test cases near a (normalized) test that
also fail.  For example, the value 1 assigned to {\tt int0} in step 0
is not essential.  It could be changed to any value in the range 5-20
(1-20 is the range of values allowed by the test generator) without
changing the final result.  The same is true of the assignment of 3 to
{\tt int1}.  Similarly, the exact ordering of many steps in the test
case is not important.  Finally, step 9 is annotated to show that
instead of using the existing value of {\tt int1} (4), a fresh
assignment could be inserted before the {\tt delete} call, setting
{\tt int1} to 3 instead.  These possible changes are not meant to be
combined --- the annotation claims only that changing these aspects of
the test case one at a time will preserve failure.  This annotation
provides information allowing a user to understand that a single test
case is representative of a \emph{family} of test cases that cause the
same kind of failure.

Combining normalization and generalization avoids some common problems
with understanding automatically generated test cases.  For instance,
when a large integer appears in such a test case, the question always
arises --- is this unusual value important, or just a random number of
no significance \cite{MakeMost}?  After normalization, any large
values in a test case are essential, rather than
accidental, because normalization includes value minimization.
Without the additional step of generalization it would be
easy to assume all small numeric values in normalized
tests are accidental.  Generalization informs a user when a small
value is required to reproduce a failure, and when it is simply an
artifact of normalization.

Normalization is not yet a complete solution to the problem of identifying
distinct faults (e.g., our algorithms do not apply to complex custom
test generators such as Csmith \cite{csmith} or {\tt jsfunfuzz}
\cite{jsfunfuzz}), but it is often highly effective.  Running 100,000
tests (of length 100) on the faulty AVL tree produces 860 failing test
cases with no duplicates.  Normalizing these reduces the number of
distinct failing test cases to just 22.  Ideally \emph{all} failures
due to the same fault in the SUT (Software Under Test) would normalize
to a single, representative test case.  We aim to
\emph{approximate} such a canonical form for faults.  Figure \ref{diffnorm},
in Section \ref{formalexample}, shows an AVL tree test case that
normalizes differently.  The graph structure required for the {\tt
  delete} fault results in an
unusually poor effectiveness for normalization.  In experiments with 82 AVL tree faults,
the mean number of distinct failures after normalization for 1,000
tests was just 3.1 (with median 2). This fault, in contrast, produced 18
distinct failures.  Nonetheless, determining that the failure in Figure
\ref{diffnorm} (or one of the similarly structured other 20 failures)
is due to the same fault as the failure in Figure \ref{normalgen}
should be much less difficult than performing the same task over many hundreds of failures with much more extreme variation. 

The contributions of this paper are 1) normalization and
generalization for API-based test cases, key steps towards a goal of
``one test case to rule them all'' (per fault), 2) algorithms for
normalization and generalization that make use of the abstract
interface for testing provided by the TSTL \cite{tstl,NFM15,ISSTA15}
domain-specific language (DSL) \cite{Fow10}, and 3)
experimental results showing the value of normalization and
generalization.  Normalization preserves fault detection approximately
as well as test case reduction via delta-debugging, and often reduces
the set of test cases to be examined by more than an order of
magnitude. In many cases, the normalization is perfect (one test case
per fault).  Normalization and generalization have also been useful in
understanding complicated test cases for a variety of software
systems, including TSTL itself, the NumPy library for numeric
computation, and ArcPy, a widely-used, highly complex package for
Geographic Information System (GIS) automation.

\begin{figure}[t]
{\scriptsize
{\bf Test case \#1}\hspace{0.415in} {\bf Test case \#2} \hspace{0.41in}
{\bf Test case \#3}
\begin{verbatim}
avl0 = avl.AVLTree()   int0 = 14              avl1 = avl.AVLTree()
int0 = 4               avl0 = avl.AVLTree()   int3 = 18 
int2 = 13              int2 = 13              avl1.insert(int3) 
int3 = 7               int1 = 15              int0 = 5 
avl0.insert(int2)      avl0.insert(int1)      int3 = 12 
avl0.insert(int3)      int1 = 11              avl1.insert(int0) 
int1 = 15              avl0.insert(int2)      int0 = 15 
avl0.insert(int1)      avl0.insert(int0)      avl1.insert(int0) 
avl0.insert(int0)      avl0.insert(int1)      avl1.insert(int3) 
avl0.delete(int2)      avl0.delete(int0)      int1 = 15 
                                              avl1.delete(int1) 
\end{verbatim}
}
%\vspace{-0.2in}
\caption {\scriptsize{Three random test cases for one fault.}}
\label{threetests}
%\vspace{-0.15in}
\end{figure}

\begin{figure}[t]
{\scriptsize
\begin{code}
\textcolor{black!60}{\#[}
int0 = 1                              \textcolor{black!60}{\# STEP 0}
\textcolor{black!60}{\#  or int0 = 5 }
\textcolor{black!60}{\#   - int0 = 20} 
\textcolor{black!60}{\#  swaps with step 4}
int1 = 3                              \textcolor{black!60}{\# STEP 1}
\textcolor{black!60}{\#  or int1 = 5 }
\textcolor{black!60}{\#   - int1 = 20} 
\textcolor{black!60}{\#  swaps with step 6}
avl0 = avl.AVLTree()                  \textcolor{black!60}{\# STEP 2}
\textcolor{black!60}{\#] (steps in [] can be in any order)}
avl0.insert(int0)                     \textcolor{black!60}{\# STEP 3}
\textcolor{black!60}{\#[}
int0 = 2                              \textcolor{black!60}{\# STEP 4}
\textcolor{black!60}{\#  swaps with step 0}
avl0.insert(int1)                     \textcolor{black!60}{\# STEP 5}
\textcolor{black!60}{\#] (steps in [] can be in any order)}
int1 = 4                              \textcolor{black!60}{\# STEP 6}
\textcolor{black!60}{\#  or int1 = 5 }
\textcolor{black!60}{\#   - int1 = 20} 
\textcolor{black!60}{\#  swaps with step 1}
avl0.insert(int1)                     \textcolor{black!60}{\# STEP 7}
avl0.insert(int0)                     \textcolor{black!60}{\# STEP 8}
avl0.delete(int1)                     \textcolor{black!60}{\# STEP 9}
\textcolor{black!60}{\#  or (}
\textcolor{black!60}{\#      int1 = 3  ;}
\textcolor{black!60}{\#      avl0.delete(int1) }
\textcolor{black!60}{\#     )}
\end{code}
}
\caption{\scriptsize{Normalization and generalization for all three test cases.
  Lines beginning with \# are comments in Python, used for annotations.}}
\label{normalgen}
\end{figure}

