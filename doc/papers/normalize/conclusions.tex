\section{Conclusions and Future Work}

This paper introduces test normalization and generalization.  The
methods presented are significant steps towards a difficult goal:
providing users of automated testing with a \emph{single test, as
  short and simple as possible, for each underlying fault in the SUT},
and \emph{annotations describing the general conditions under which
  the fault manifests as failure}.  Normalization approaches this
ideal by rewriting numerous distinct failing tests into a smaller,
often minimal, set of simpler tests.  Generalization uses automated
experiments to distinguish essential and accidental elements of a
test.  In our experiments, normalization reduced the number of
failures to examine by well over an order of magnitude, often to the
ideal of one per fault.  The algorithms for normalization and
generalization depend only a (possible somewhat arbitrary) total order
over test actions and an abstract form for tests, suitable for term
rewriting.  It is therefore likely applicable to any source language
and many different test generation methods, including those that
already produce short tests \cite{FA11,SoftBET}.  TSTL-based
normalization and generalization is currently available in a
well-tested Python version \cite{tstl,ISSTA15}; there is also a beta version, with more limited
normalization, for Java.


The goal of normalization and generalization can also be pursued in
settings other than API sequence or string grammar testing.  The
difficulties of defining a normal form for JavaScript \cite{jsfunfuzz}
or C \cite{csmith} tests are non-trivial, but not obviously
overwhelming \cite{CReduce}. Less effective methods
than ours might still aid debugging and assist fuzzer taming
\cite{PLDI13}.  Simple generalization (e.g., is this numeric constant
essential, can these two statements be swapped?) and a limited form of
fresh value generalization should be easy to apply, even for complex
programming language tests.  

The working version of  TSTL \cite{tstl} includes
support for normalization and generalization.  Further experimental
evaluation of normalization and generalization over more SUTs is
important to quantify effectiveness and motivate new rewrites and
generalizations.  The TSTL implementations are designed to allow these
to be easily added, in order to bring testing closer to the
goal of ``one test to rule them all.''
