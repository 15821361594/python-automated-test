\section{Introduction}

Software test automation can be divided into two types: (1) automated
execution and determination of results for human-created tests, and
(2) automatic generation of tests.  Both are critical for effective,
efficient software testing, but only automatic generation offers the
promise of discovering faults without human determination that a
particular execution scenario has the potential to behave incorrectly.
Automated generation of tests relies on the construction of \emph{test
  harnesses}.  A \emph{test harness} defines the set of valid tests
(and, usually, a set of correctness properties for those tests) for
the Software Under Test (SUT).  This paper presents a language and
tools applying insights from the world of explict-state model
checking to the problem of producing test harnesses for automated
test generation.

Building a test harness is a task that even expert users of model
checkers or automated testing often find painful
\cite{woda08,woda12}.  The difficulty of harness generation is one
reason for the limited adoption of sophisticated testing and model
checking by the typical developer who writes unit tests.  This is
unfortunate, as even simple random testing can often uncover subtle
faults.

The ``natural'' way to write a test harness is as code in the language
of the SUT.  This is obviously how most unit
tests are written, as witnessed by the proliferation of tools like
JUnit \cite{JUnit} and its imitators (e.g., PyUnit, HUnit, etc.).  It
is also how many industrial-strength random testing systems are
written \cite{ICSEDiff,AMAI}.  A KLEE ``test harness'' \cite{KLEE} for
symbolic execution is written in C, with a few additional constructs
to indicate which values are symbolic.  This approach is common in
model checking as well: e.g., Java Pathfinder \cite{JPF,JPF2} can
easily be seen as offering a way to define a state space using Java
itself as the modeling language, and CBMC \cite{CBMC,CBMCp} performs a
similar function in C, using SAT/SMT-based bounded model checking
instead of explicit-state execution.  JPF in particular has shown how
writing a harness in the SUT's own language can make it easy to
perform ``apples to apples'' comparisons of various testing/model
checking strategies \cite{JPFRandTest}.


\begin{figure}[b]
{\scriptsize
\begin{code}
op = choice(operations);
val1 = choice(values);
val2 = choice(values);
if (op == op1 \&\& guard1) \{
    call1(val1);
\} else if (op == op2 \&\& guard2) \{
    call2(val1,val2);
\} else if (op == op3 \&\& guard3) \{
    call3(val1,val2);
...
\end{code}
}
\vspace{-0.15in}
\caption {A test harness in the SUT language}
\label{fig:badharness}
\end{figure}

Unfortunately, writing test harnesses this way is a highly repetitive
and error-prone programming task, with many conceptual ``code clones''
(e.g. Figure \ref{fig:badharness}). A user faces difficult choices in
constructing such a harness. For example, the way guards and choices
are interleaved means that the state-space will be pointlessly
expanded to include many action and value choices that don't produce
any useful behavior.  This harness also always assigns {\tt val2} even
though {\tt call1} only uses {\tt val1}, to avoid having to repeat the
choice code for calls 2 and 3.  Moreover, this harness is possibly
sub-optimal for a method such as random testing, where the lack of any
memory for previously chosen values can make it hard to exercise code
behaviors that rely on providing the same arguments to multiple method
calls (e.g., {\tt insert} and {\tt delete} for container classes).
The construction of a harness becomes even more complex in realistic
cases, where the tested behaviors involve building up complex types as
inputs to method calls, rather than simple integer choices. For
example, consider the problem of testing a complex Python library.  Figure
\ref{fig:MakeFeatureLayer} shows a portion of the Python documentation for one function in the ArcPy site
package for Geographic Information System (GIS) automation.  Rather than taking a single integer, this
function call requires complex inputs --- a feature class or
layer, an SQL expression, and other complex types that we can assume
are also difficult to construct.  A harness testing a typical
real-world library must manage the creation of values of multiple complex types.
Moreover, because building up function inputs is itself complicated
and requires complex method calls, they cannot simply be produced on each iteration, but must be
remembered.  As the interactions of multiple instances of certain
types are often a source of behavioral complexity,
the harness needs to decide how many objects of each type to store.
The code quickly becomes hard to read, hard to maintain, and hard to
debug.  In some cases \cite{AMAI} the code for a sophisticated test
harness approaches the SUT in complexity and even size!  The code's
structure also tends to lock in many choices that would ideally be configurable.

\begin{figure}[t]
{\scriptsize
\begin{code}
MakeFeatureLayer\_management(in\_features, out\_layer, {where\_clause}, {workspace}, {field\_info})
   
   Creates a feature layer from an input feature class or layer file. The layer
   that is created by the tool is temporary and will not persist after the session
   ends unless the layer is saved to disk or the map document is saved.
    
INPUTS:
 in\_features (Feature Layer):
   The input feature class or layer from which to make the new layer. Complex
   feature classes, such as annotation and dimensions, are not valid inputs to this tool.
 where\_clause \{SQL Expression\}:
   An SQL expression used to select a subset of features. For more information on
   SQL syntax see the help topic SQL reference for query expressions used in ArcGIS.
...
\end{code}
}
\caption{Documentation for a function in Esri's ArcPy site package.}
\label{fig:MakeFeatureLayer}
\end{figure}

One of the most important of these is the choice of test generation
method.  Writing a harness by hand usually makes it hard to try out
new strategies.   Writing novel testing strategies in even such
an extensible platform as Java Pathfinder is hardly a task for the
non-expert.
The harness in Figure \ref{fig:badharness} may support random testing and
some form of model checking, if it is written in Java and can use JPF
or a library for adaptation-based testing \cite{ISSRE12}. Such a
harness cannot support model checking or any other sophisticated strategy
without being re-written if it is in a language like Python without
verification tool support.

What the user really wants is to simply provide a concise version of the information in
Figure \ref{fig:MakeFeatureLayer}, some configuration details (e.g., how many
feature classes to work with), and some information on which testing
method to use (e.g., model checking, random testing, machine-learning
based approaches).  Some automated testing tools for Java \cite{FA11,Pacheco}
take a variation on this approach, automatically extracting the
signatures of methods from source code and testing them.
Unfortunately, completely automatic extraction often fails to handle
the subtle details of harness construction, such as defining guards
for some operations, or temporal constraints between API calls that
are not detectable by simple exception behavior.  Understanding
problems with automatic extraction can be hard with large libraries,
since the extraction tends to either produce internal data structures
only or produces a huge, impenetrable mass of code. The user \emph{wants} a
declarative harness, but often \emph{needs} to program critical details of a
harness, and build understanding of the system by performing harness development in
small, incremental steps.

\subsection{Domain Specific Languages for Testing}

The nature of test harness construction suggests the use of a
\emph{domain-specific language} (DSL) for testing \cite{ISOLA12}.  DSLs
\cite{Fow10} provide abstractions and notations to support a
particular programming domain. The use of DSLs is a formalization of
the long-standing approach of using ``little languages'' in computer
science, as memorably advocated by Jon Bentley in one of his famous
Programming Pearls columns \cite{LitLang} and exemplified in such system
designs as UNIX.  DSLs typically come in two forms: \emph{external}
and \emph{internal}.  An external DSL is a stand-alone language, with
its own syntax.  An internal DSL, also known as a domain-specific
embedded language (DSEL), is hosted in a full-featured programming
language, restricting it to the syntax (and semantics) of that
language.  Many attempts to define harnesses can be seen as internal
DSLs \cite{UDITA,ISSRE12,JPF2,CBMCp,KLEE}.  Neither of these choices
is quite right for test harnesses.  Simply adding operations for
nondeterministic choice still leaves most of
the tedious work of harness definition to the user, and makes changing
testing approaches difficult.  With an external DSL, the user
must learn a new language, and the easier it is to learn, the less
likely it is to support the full range of features needed.

A novel approach is taken in recent versions of the SPIN model checker
\cite{SPIN}.  Version 4.0 of SPIN \cite{ModelDriven} made use of
SPIN's nature as a tool that \emph{outputs a C program} to allow users
to include calls to the C language in their PROMELA models.  The
ability to directly call C code makes it much easier to model check
large, complex C programs \cite{AMAI,ModelCode}.  C serves as a
``DSEL'' for SPIN, except that, rather than having a domain-specific
language inside a general-purpose one, here the domain-specific
language hosts a general-purpose language.  A similar embedding is
used in {\tt where} clauses of the LogScope language for testing Mars
Science Laboratory software \cite{scriptstospecs}.  We adopt this
approach for our own language and embed the general-purpose language (for expressiveness) in a
DSL (for concision and ease-of-use).

\subsection{TSTL: The Template Scripting Testing Language}

TSTL is based on understanding the test harness as a \emph{declaration
  of the possible actions the SUT can take}, where these actions are
\emph{defined in the language of the SUT itself, with the full power
  of the programming language to define guards, perform
  pre-processing, and implement oracles}.  Our particular approach is
based on what we call \emph{template scripting}.

The \emph{template} aspect is based on the fact that our method
proceeds by processing a harness definition file to output code that
enables testing, much like SPIN does with C code.  The harness
description file consists of fragments of code in the SUT's language
that are expanded, via the TSTL compiler, into executable source code.
The tool that outputs code basically defines a \emph{template} for
test harnesses in a programming language, and the harness definition
tells the tool how to instantiate that template.  Rather
than generating a testing tool (what SPIN does, essentially), our method outputs \emph{a class
defining a search space}, which can then be interfaced to any testing
strategy to generate and manipulate tests.  The \emph{scripting} aspect simply means
TSTL is designed to be very lightweight and as easy for
users to pick up as popular scripting languages, like Python.  TSTL
works best when the SUT language is very
concise, like most scripting language, making ``one-liners'' of action definition possible.

\begin{figure}
{\scriptsize
\begin{code}
@import arcpy
@from arcpy import ExecuteError
\vspace{0.1in}
pools:
  <featureclass> 2 CONST
  <newlayer> 2 CONST
  <op> 2 CONST 
  <val> 2 CONST
  <whereclause> 2 CONST
\vspace{0.1in}
actions:

<featureclass> := <["file1.shp", "file2.shp", "file3.shp"]>
<newlayer> := <["newl1", "newl2", "newl3"]>

<op> := <[">", "<", "<=", ">=", "=", "!="]>
<val> := <1..10>
<val> = <val> * 10
<val> = <val> + 1

<whereclause> := '"' + <fieldname> + '" ' + <op> + str(<val>)
<whereclause> := '"' + <fieldname> + '" IS NULL'
<whereclause> := '"' + <fieldname> + '" IS NOT NULL'
<whereclause> = <whereclause> + ' AND ' + <whereclause>
<whereclause> = <whereclause> + ' OR ' +  <whereclause>
<whereclause> = 'NOT' + <whereclause>

\{ExecuteError\} arcpy.MakeFeatureLayer\_management(<featureclass>,<newlayer>)

\{ExecuteError\} arcpy.MakeFeatureLayer\_management(<featureclass>,<newlayer>,
  where\_clause=<whereclause>)
\end{code}
}
\caption{A small TSTL file to test one ArcPy function.}
\label{fig:makefeaturelayer}
\end{figure}

\begin{figure}
{\scriptsize
\begin{code}
import sut random, time
sut = sut.sut()
NUM\_TESTS = 1000
TEST\_LENGTH = 200 
for t in xrange(0,NUM\_TESTS):
   sut.restart()
   T = []
   for s in xrange(0,TEST\_LENGTH): 
       action = sut.randomEnabled()
       T.append(action)
       r = sut.safely(action)
       if sut.newBranches() != []
          print time.time(),'NEW BRANCHES:', sut.newBranches()
       if (not r) or (not sut.check()):
          pred = sut.failsCheck if r else sut.fails
          print 'TEST FAILED:', sut.error() 
          R = sut.reduce(T, pred)
          N = sut.normalize(R, pred) 
          sut.generalize(N,pred)
\end{code}
}
\caption{A simple random tester using the interface provided by TSTL.}
\label{fig:rt}
\end{figure}

Figure \ref{fig:makefeaturelayer} shows a simple TSTL harness for the
function documented in Figure \ref{fig:MakeFeatureLayer}.  This
code can generate calls that include a choice between three files that
contain GIS data, three names for new layers generated, and even
construct SQL where clauses of arbitrary length.  Figure \ref{fig:rt}
shows a simple pure random test generator that can test \emph{any} SUT
with a TSTL-defined harness.  This harness, in 20 lines of code, not
only provides automated test generation, but continuous reporting of
incremental branch coverage, delta-debugging \cite{DD}
based reduction of failing tests, and additional TSTL-specific
post-processing that further reduces the size and complexity of test
cases for debugging.  The brevity of the test generator, no matter how complex the
SUT, is made possible by the functionality of all TSTL-generated
testing interfaces.

\subsection{Contributions}

We showcase the TSTL approach and tools using an ongoing case study,
applying TSTL and its tool suite to a large, real-world software
library used in critical applications.  The test effort has been driven and directed not by a
software testing researcher (as is the usual case), but by a domain
expert in the Geographic Information System (GIS) SUT.  In the
process, multiple faults and undocumented restrictions of the library
under test have been discovered, and the TSTL language and tool suite have
been improved.

This paper presents the first complete presentation of the TSTL
langauge and tools, with enough information on the language and the
testing API TSTL provided for two critical purposes:

\begin{itemize}
\item First, would-be users wanting to take advantage of automated
  test generation should be able to base their own testing
  efforts using TSTL on the example code in this paper.
  This paper thus serves as a basic ``TSTL cookbook.''

\item Second, researchers should be able to use the information in this paper to
  extend existing TSTL tools or build their own tools to explore novel
  test generation strategies, automated debugging methods, and other
  research prototypes.  TSTL enables easy comparison of
  methods in a framework reducing the burden of implementation
  and avoiding irrelevant differences in performance due to underlying
  infrastructure.  The growing set of SUTs
  included in the TSTL distribution can serve as bases for
  experimental efforts, and include large and widely used Python
  software systems.
\end{itemize}

\section{Esri ArcPy}


Esri is the single largest GIS software vendor, with about 40\% of
global market share.  Esri's ArcGIS tools are extremely widely used
for GIS analysis, in government, scientific research, commercial
enterprises, and education.  Automation of complex GIS analysis and
data management is essential, and Esri has long provided tools for
programming their GIS software tools.  The newest such method,
introduced in ArcGIS 10.0, is a Python site-package, ArcPy
\cite{ArcPy}.  ArcPy is a complex library, with dozens of classes and
hundreds of functions distributed over a variety of of toolboxes.
Most of the code executed in carrying out ArcPy functions is the code
for the ArcGIS engine itself.  This source code, written in C++
(amounting to millions of lines), is
not available.  The source code for the latest version (10.3) of the
Python site-package alone, however, which interfaces with the ArcGIS
engine, is over 50,000 lines of code.  This is a very large system
(especially given the compactness of Python code), comparable in size
to the largest software systems previously tested using automated test
generation, such as core Java and Apache libraries
\cite{FA11,Pacheco}.

In order to improve the reliability of ArcPy, we are developing a
framework for automated testing of ArcPy itself, as well as libraries
based on ArcPy.  The TSTL harness for ArcPy is already more than six times as
large as the next-largest such definition previously implemented in
TSTL, even though the harness so far only includes a small portion of ArcPy
API (Application Program Interface) calls. The first stage of testing has resulted in discovery of
multiple faults in ArcPy/ArcGIS, and has required modifications to the
TSTL language and, especially, to the toolchain supporting test replay,
debugging, and test case understanding.

%One of the contributions of this paper is a more in-depth discussion
%of the problems, challenges, and tool utility aspects of testing
%software than is typical in most research papers in the field.  Such
%papers are (understandably) typically focused on novel algorithms or
%empirical evaluations of known methods, rather than the practical aspects of finding
%and understanding faults in a real-world software system.


%\subsection{Automated Testing for the Rest of the World}

Previous work on automated testing for APIs has been largely carried
out by software testing researchers only, or (at most) by software
testing researchers working with individuals who are primarily
software developers.  This paper presents work largely directed by
the first author, who is not a software developer by
profession or education, but a GIS analyst.  

The problem of end-user testing
\cite{burnettEUSE,Silos,rothermelTOSEM} is known to be difficult.
Previous work has focused on end-users of systems that are not
traditional programming languages: e.g. spreadsheets
\cite{rothermelTOSEM}, visual languages, or machine-learning systems
\cite{OnlyOracle}.  TSTL is partly designed to allow a user who is
familiar with a software library but not expert in software testing
techniques to test a traditional software API library.  In one sense,
this is a less difficult end-user testing scenario than spreadsheets
or visual forms, in that the testing is directed by an individual used
to writing and thinking about source code.  The concepts in
modern automated software testing are most easily understood by those
who are also familiar with the structure and semantics of conventional
programming languages.  On the other hand, the system to be tested is
large, not a small user-developed program but a very large, complex, system.
ArcPy was also not written by the end-user, or by any of the authors
of this paper, nor have the authors received any assistance in the
effort from Esri.

Automated testing systems more advanced than a simple hand-written loop generating 
a few random inputs to a handful of functions, or more complicated to 
use than a fully push-button system are often considered too difficult 
for practical use even by software developers or software QA staff \cite{ISSRE12}.
In fact, in the experience of the second author of this paper (an
academic software testing researcher), even ``push-button'' tools for
automated testing are often difficult for expert users to install, apply, and
configure \cite{AMAI,CFV08,ISSRE12}.  TSTL aims to be relatively easy to
use for anyone familliar with basic Python development.  By avoiding
the use of a toy problem and presenting TSTL in the context of a more
typical real-world system than a simple container class, we hope to
make it easier to apply to other real-world systems.
%One goal of this work
%has been to mature the TSTL language and toolchain so Python
%programmers from all backgrounds can easily apply it to their
%automated testing problems, with tools approximately as easy to use as
%other Python developer tools.

%The second major contribution of this paper is therefore a presentation of an
%approach to automated testing that has been chosen by a GIS analyst, not a
%software developer or testing researcher.  Moreover, we present this
%paper as a proof-of-concept that modern automated testing, even in a
%highly interactive, non-push-button form, can be used by a motivated
%domain expert, with the support of  a domain-specific language
%\cite{Fow10} and a set of tools for generating, analyzing, and replaying tests.


