Test case reduction has long been seen as essential to effective automated testing.  However, test case reduction simply reduces the \emph{length} of a test case.  It does not attempt to reduce \emph{semantic} complexity.  This paper presents algorithms for normalizing and generalizing test cases.  Rewriting test cases into a \emph{normal form} can reduce semantic complexity and, often, reduce the length of an already reduced test case.  Most importantly, normalization can reduce the \emph{number} of test cases that a reader must examine, partially addressing the ``fuzzer taming'' problem of discovering all faults in a large set of failing test cases.  Generalization, in contrast, takes a test case and reports what aspects of the test could have been changed while preserving the property that the test fails.  These algorithms rely on the features of a recently introduced automated testing DSL, TSTL.  Normalization plus generalization aids understanding of test cases, including tests for TSTL itself and for complex and widely used Python APIs such as the NumPy numeric computation library and the ArcPy GIS scripting package.  In experiments normalization frequently reduces the number of test cases to be examined by \emph{over an order of magnitude}, and often to just one test case per fault, with fault detection preservation similar to that of traditional delta-debugging.  Together, ideally, normalization and generalization allow a user to replace reading a set of test cases that vary in unimportant ways with reading \emph{one annotated test case} (per fault) that succinctly describes a family of failures. 