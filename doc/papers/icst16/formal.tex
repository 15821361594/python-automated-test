\section{Formal Definitions of Normalization and Generalization}

\subsection{A Brief Introduction to TSTL}

\begin{figure}
{\scriptsize
\begin{code}
@import avl

pool: <int> 4 CONST
pool: <avl> 3

property: <avl>.check\_balanced()

<int> := <[1..20]>
<avl> := avl.AVLTree()

<avl>.insert(<int>)
<avl>.delete(<int>)
<avl>.find(<int>)
<avl>.inorder()
\end{code}
}
\caption{Part of a TSTL definition of AVL tree tests}
\label{fig:example}
\end{figure}

\begin{figure}
{\scriptsize
\begin{code}
avl1 = avl.AVLTree()  
int3 = 10  
int1 = 11  
avl1.insert(int1) 
int1 = 1  
avl1.insert(int3) 
avl1.insert(int1) 
int3 = 9  
avl1.insert(int3) 
int2 = 11  
avl1.delete(int2) 
\end{code}
}
\caption{An example TSTL-produced test}
\label{fig:avlrun}
\end{figure}

TSTL \cite{NFM15,ISSTA15} is a language for defining the structure of
test cases, and a set of tools for use in generating, manipulating,
and understanding those test cases.  Figure \ref{fig:example} shows a
simplified portion of a TSTL definition of tests of an AVL tree class,
in the latest syntax for TSTL (which differs slightly from that in the
cited papers introducing TSTL).  TSTL provides numerous features not
shown in this small example, including automatic differential testing,
complex logging, support for complex guards, and use of pre- and post-
values.  Given a harness like the one in Figure \ref{fig:example},
TSTL compiles it into a class file defining an interface for testing
that provides features such as querying the set of available testing
actions, restarting a test, replaying a test, collecting code coverage
data, and so forth.  The TSTL release
(\url{https://github.com/agroce/tstl}) also provides some testing
tools that make use of this interface to generate tests and provide
other debugging capabilities.

The key point for our purposes is merely that a TSTL test harness
defines a set of \emph{pools} that hold values produced and used
during testing \cite{AndrewsTR} (a common approach to defining
API-testing sequences) and a set of actions that are possible during
testing, typically API calls and assignments to pool values.  In this
example, there are two pools, one named {\tt int} and one named {\tt
  avl}.  There are four instances of the {\tt int} pool, which means
that a test in progress can store up to 4 {\tt int}s at one time (in
variables named {\tt int0}, {\tt int1}, {\tt int2}, and {\tt int3}), and three
instances of the {\tt avl} pool.  The actions defined here are setting
the value of an {\tt int} pool to any integer in the range 1-20
inclusive, setting the value of an {\tt avl} pool to a newly
constructed AVL tree, and calling an AVL tree's {\tt insert}, {\tt
  delete}, {\tt find} and {\tt inorder} methods.  Figure \ref{fig:avlrun}
shows a valid test case produced by running a random test generator on
the TSTL-compiled interface produced by this definition.  TSTL handles
ensuring that tests are well-formed: for example, no pool instance
(such as {\tt avl1} can appear in an action until it has been assigned
a value), and no pool instance that has been assigned a value can be
assigned a different value until it has been used in an action, to
avoid degenerate sequences such as {\tt int3 = 10} followed by {\tt
  int3 = 4}.  Each action in a test case is called a ``step'' --- the
first step of the example test is storing a new AVL tree in {\tt
  avl1}, for example.

The definition of pools and actions in TSTL defines a \emph{total
  order} on all actions.  First, actions are ordered by their position
in the definition file.  All {\tt insert} actions are therefore before
all {\tt delete} actions, and all {\tt delete} actions are before find
actions.  Of course, one line of TSTL defines many actions, because of
the choices for pools.  For example, the line {\tt
  <avl>.insert(<int>)} defines 12 actions, one for each choice of {\tt
  avl} and {\tt int} pool instance.  These are ordered lexically, in
the obvious way ({\tt avl0} preceeds {\tt avl1}, etc.).  Value ranges
such as in the {\tt int} initialization, are also ordered in the
natural way, with lower values first.  Given this total order, each
action can be assigned a unique index, from 0 up to 1 less than the
total number of actions. Initially, this ordering (and
numbering) for each action was intended to allow for a kind of
Goedel-numbering of tests, for proving certain mathematical properties
\cite{AndrewsTR}.  However, it also allows us to concisely define a
practical method for normalizing and generalizing test cases.

One note: in normal TSTL semantics, the action sequence that assigns a
value to the same pool twice in a row is not allowed --- until a pool
value is used, it cannot be assigned to again.  However, during
normalization and generalization, this restriction is removed.  The
restriction exists only to prevent the generation of un-interesting
test sequences.  The normalization and generalization algorithms avoid
such sequences by other means, and allowing over-writing assignments
makes normalization much more effective.  Such sequences only appear
in intermediate steps; after normalization, test
cases are guaranteed to not have any remaining sequences invalid in
normal TSTL semantics.

\subsection{Normalization}

A test-case normalization algorithm has a simple goal:  we ideally aim to
produce a function $f : t \rightarrow t$ (a function that takes a test
case and returns a test case) such that:

\begin{enumerate}
\item If $t$ fails, $f(t)$ fails.
\item If $t$ and $t'$ fail due to the same fault, $f(t) = f(t')$.
\item If $t$ and $t'$ fail due to different faults, $f(t) \not=
  f(t')$.
\end{enumerate}

Such a function would define a true \emph{canonical form} for test cases, where
each underlying fault is uniquely represented by a single test case.
In general, it seems clear that defining such an $f$ is (at least) as
difficult as automatic fault localization and repair.  Therefore, we
aim at approximating the goal, by providing a set of simple
transformations such that $f$ reduces many tests to the same test, has
low probability of reducing two tests failing for different reasons
into the same test, and $f$ is not unreasonably expensive to compute.
The implementation for $f$ (in fact, for a family of $f$-approximating
functions, with different tradeoffs in runtime and level of
normalization) involves defining a set of rewrite rules such that for a
test $b$ (the base test), the rules define a finite set of candidate
tests $c \in C(b)$, possible simplifications of $b$, where each $c$ is
the result of applying some rewrite, $r_i$ to $b$.  The notion of
simplicity is defined by a restriction on the rewriting rules.  For
any test case $t$, let $R(t)$ be the length of the maximum number of
rewrites that can be applied to $t$, e.g., the longest possible
sequence such that $c_0 = r_{i1}(t), c_1 = r_{i2}(c_0), ... c_n = r_{in}(c_{n-1})$. We
require that $\forall c \in C(b), R(c) < R(b)$.  The number of possible
rewrites for each candidate must be smaller than the number of
possible rewrites for $b$.  This implies further restrictons, e.g., no
rewriting can ever reverse another rewrite's effects.  Such a rewrite
system is \emph{strongly normalizing}:  any sequence of rewrites
chosen will eventually end in a term (test case) that cannot be
further rewritten.

In the setting of TSTL, where test actions and have a defined total
order, a simple principle can be applied to produce strongly
normalizing rewrite rules: rewrites should reduce the sum of the
indices of the actions in the test case.  This approach
provides effective normaliization at a significant, but not
unreasonable, computational cost.

\subsubsection{Definitions and Notation}

In order to formally define normalization, some additional notation is required.
A \emph{step} is an action paired with an index indicating its position in a text,
where the first action is step 0, etc., e.g.: $(2: a)$ indicates the
third step of the test is action $a$ (indexing is from 0). 
$\Delta(t,t')$ is the set of all steps in $t$ such that $t(i) \not= t'(i)$.

We use the $<$ operator over various types:
$a < b$ iff the index of action $a$ is lower
than that of action $b$.  We compare steps with $<$ by comparing their
actions --- $(i,a) < (j,b)$ iff $a < b$.  For a set or sequence of actions or steps, we define the $min$ of the
set to be the lowest indexed action in the set, and use
these to compare sets:  $s_1 < s_2$ iff $min(s_1) < min(s_2)$. For pools,
$p < p'$ if and only if $p$'s index is lower than the index for $p'$
\emph{and} $p$ and $p'$ are from the same pool.

The rewrite $t[x \Rightarrow y]$ denotes the test t with all instances of $x$
replaced by $y$.  Here, $x$ and $y$ can be actions, steps, or pools.
$t[x \Leftrightarrow y]$ is similar, except that $x$ and $y$ are
swapped.  Rewrite $t(i,j)[x \Rightarrow y]$ is the same as $t[x \Rightarrow
y]$, except that the replacement is only applied between steps $i$ and
$j$, inclusive.  Finally, $t_i(x)$ denotes $t$ with all steps
containing $x$ that are before step $i$ moved to step $i$, preserving
their previous order, and moving steps at $i$ and after $i$ to make room.

\subsubsection{Rewrite Rules}

\begin{enumerate}
\item {\bf SimplifyAll:}
$c = b[a \Rightarrow a']$\\
\-\ \ \ \emph{where} $a' < a$\\
Covers the case where all appearances of an action can be replaced with a 
simpler (lower-indexed) action. 
\item {\bf ReplacePool:}
$c = b(i,j)[p \Rightarrow p']$\\ 
\-\ \ \ \emph{where} $p < p'$ and $0 \leq i < j <
|b|$\\
Covers the case when all appearances of an instance of a pool can be replaced with 
a lower-indexed instance of that pool (with possible restriction to a range of steps).
\item {\bf ReplaceMovePool:}
$c = b_{\rightarrow i}(p')[p \Rightarrow p']$\\
\-\ \ \ \emph{where} $p < p'$ and $0
\leq i < |b|$\\
Covers the case when all appearances of an instance of a pool can be replaced with
a lower-indexed instance of that pool, if all assignments to the new instance before a
certain step are moved to that step.
\item {\bf SimplifySingle:}
$c = b[(i: a) \Rightarrow (i: a')]$\\
\-\ \ \ \emph{where} $a' < a$\\
Covers the case where one action can be replaced with a 
simpler (lower-indexed) action. 
\item {\bf SwapPool:}
$c = b(i,j)[p \Leftrightarrow p']$\\
\-\ \ \ \emph{where} $\Delta(c,b) < \Delta(b,c)$\\
\-\ \ \ and $0 \leq i < j < |b|$\\
\-\ \ \ and $p < p'$\\
Covers the case where swapping two pool instances (within a range of steps) reduces
the minimal action index of the modified steps.
\item {\bf SwapAction:}
$c = b[(i: a) \Rightarrow (i: b), (j: b) \Rightarrow (j: a)]$\\
\-\ \ \ \emph{where} $i < j$ and
$b < a$\\
Covers the case where two actions can be swapped in the test, with the
lower-indexed action now appearing earlier.
\item {\bf ReduceAction:}
$c = b[(i: a) \Rightarrow (i: a')]$\\
\-\ \ \ \emph{where} $|ddmin(c)| < |ddmin(b)|$\\
Covers the case where an action can be replaced by any action (not just lower-indexed
actions) and this enables further delta-debugging-based reduction of
the test case's length.
\end{enumerate}

\subsubsection{Normalization Algorithm}

These rules alone do not determine a complete normalization method; it is
also required to determine an order in which they are applied.  The
order in our default implementation is the order above, with the
modification that in practice the {\bf ReplacePool} and {\bf
  ReplaceMovePool} rewrites are both performed at once, interleaved
(e.g., for every possible replacement of a pool, both rules are
checked, in the order given above).  The core algorithm, given a set
of ordered rewrite rules defining $C(b)$ is given as Algorithm
\ref{simpalg}.  Here {\tt pred} is an arbitrary predicate indicating
that the candidate test still satisfies the property of interest that
held for the original test $b$.  In most cases, this predicate will be
``the test fails'' but we also have preserved
code coverage for regression suites \cite{icst2014}.  Notice that
after applying each rewrite rule, we perform delta-debugging on the
new base test case, since often a rewrite makes other steps irrelevant.

\begin{algorithm}
\caption{Basic algorithm for normalization}
\label{simpalg}
\begin{algorithmic}[1]
\State {modified = True}
\While {modified}
\State {modified = False}
\For {$c \in C(b)$}
\If{pred($c$)}
\State modified = True 
\State $b$ = $ddmin(c)$
\State {\bf break} (exit {\bf for} loop) 
\EndIf 
\EndFor 
\EndWhile 
\State return $b$
\end{algorithmic}
\end{algorithm}

The cost of normalizing a test case is, in the worst case, extremely
large.  Consider a testing scenario where there are $n$ actions, each
of which is always enabled.  For a test case of $k$ steps, each of
which is the highest indexed action, checking the candidates produced
by the {\bf SimplifySingle} rule alone requires performing $n^k$
test executions.  If we further assume that the sequence of successful rewrites
first rewrites the final step by reducing its index by one, which
makes it possible to reduce the index of the previous step by one, and
so forth, it is easy to see that nearly $k n^k$ test case runs are
required.  In practice, the number of required test case runs is
proportional to the length of the test $k$, but most actions are not
enabled at most steps, and the rules are applied in an order that
quickly converges on a normal form.


\subsubsection{Normalization Optimizations}

The simplest and most important optimization is to improve on the
constant ordering of rewrite rules.  In our implementation, once a
rule fails to produce a candidate that satisfies {\tt pred} that rule
is moved to the end of the ordering of rewrites.  This optimization
followed the observation that almost always once a rule failed to
produce any changes in a test case, it never applied again.  This
simple change, in our experience, typically halves the time required
for normalization.

For test cases with a very short runtime, this algorithm (with reordering) is usually
practical, more expensive than delta-debugging but requiring less than
a minute to run.  However, when test case execution is expensive, the
set of candidate test cases must be further restricted.  In our
experiments, we found that restricting action replacements to cases
where the Levenshtein \cite{Lev} distance (text edit distance) between
the code for the actions was in some range was effective in reducing
runtime, while almost always having no impact on the final result.  In
practice, most test actions can only be replaced by syntactically
similar actions, without completely changing test semantics.  A
further useful optimization when normalizing large numbers of tests of
the same SUT is to cache results, so that as soon as the rewrite
sequence produces a previously seen test, the final result can be
produced (since the algorithm is deterministic).  For systems with
very expensive replay, the delta-debugging of each new base can also
be omitted, counting on the {\bf ReduceAction} rewrite to eventually
remove useless steps (however, this may come at a cost of attempts to
rewrite steps that could be removed).

Finally, it is easy
to parallelize the normalization of a test case by checking the
predicate over multiple candidates at once.  As soon as a candidate
satisfies the predicate, one of two options are available:  either the
normalization can proceed with that candidate as the new base, making
the algorithm potentially nondeterministic (in theory; in practice we
suspect the same final result will usually appear), or the algorithmc
can wait for all earlier-in-sequence candidates to be checked, and
only proceed when no candidate that would be checked first in the
sequential version of the algorithm remains in the work queue.

\subsection{Generalization}

\subsubsection{Generalization Algorithm}

The core idea of generalization is to use methods similar to those
involved in normalization to provide a user with information about
changeable aspects of a test case.  The core algorithm is simple:

\begin{algorithm}
\caption{Basic algorithm for generalization}
\label{genalg}
\begin{algorithmic}[1]
\State {swap = $\emptyset$}
\State {replace = $\emptyset$}
\For {$(i, a) \in t$}
\For {$a' : a' > a$}:
\If {pred($t[(i,a) \Rightarrow (i,a')]$)}
\State replace = replace $\cup ((i,a),(i,a'))$
\EndIf
\EndFor 
\For{$j : i < j < |t|-1 \wedge (j: b) > (i: a) $}
\If {pred($t[(i: a) \Rightarrow (i: b), (j: b) \Rightarrow (j: a)]$)}
\State swap = swap $\cup ((i,a),(j,b))$
\EndIf
\EndFor
\EndFor
\State {return (swap, replace)}
\end{algorithmic}
\end{algorithm}

This algorithm collects all steps that can be replaced with other
actions or swapped with other steps, and returns the set to be
reported to the user.  This version assumes the test has already been
normalized, but can be extended to any test case by removing the
restrictions that $a > a'$ and $(j : b) > (i : a)$.

\subsubsection{Fresh Values and Misleading Test Cases}

A side-effect of delta-debugging and of normalization is the reduction
of the number of variables used in a test case.  While usually helpful
for understanding, this can sometimes result in misleading test
cases.  In stateful systems, for example those using some kind of
cache for efficiency, putting the system into a bad state may require
building a complex object.  Once system state is corrupted, however,
the complex object is irrelevant, and its appearance in the call
leading to failure can be misleading.

As an example, consider the test case in Figure \ref{fig:mislead},
produced by our TSTL harness that uses TSTL to test TSTL itself\footnote{Since
TSTL provides a Python API, that API can be used as the SUT in
testing; we have discovered several important TSTL bugs this way.}.

\begin{figure}
{\scriptsize
\begin{code}
\textcolor{black!35}{\#[}
test0 = []                             \textcolor{black!35}{\# STEP 0}
\textcolor{black!35}{\#  or test0 = sut0.test() }
actionlist0 = sut0.actions()           \textcolor{black!35}{\# STEP 1}
\textcolor{black!35}{\#  or actionlist0 = sut0.enabled() }
\textcolor{black!35}{\#] (steps in [] can be in any order)}
action0 = actionlist0[0]               \textcolor{black!35}{\# STEP 2}
\textcolor{black!35}{\#[}
test0.append(action0)                  \textcolor{black!35}{\# STEP 3}
pred0 = sut0.fails                     \textcolor{black!35}{\# STEP 4}
\textcolor{black!35}{\#] (steps in [] can be in any order)}
sut0.normalize(test0,pred0)            \textcolor{black!35}{\# STEP 5}
sut0.normalize(test0,pred0)            \textcolor{black!35}{\# STEP 6}
\textcolor{black!35}{\#  or (}
\textcolor{black!35}{\#      test0 = []  ;}
\textcolor{black!35}{\#      sut0.normalize(test0,pred0) }
\textcolor{black!35}{\#     )}
\end{code}
}
\caption{Generalized test for TSTL itself, showing fresh-object
  generalization.}
\label{fig:mislead}
\end{figure}


\subsection{Discussion}

The essential feature of normalization and generalization as presented
in this paper is that they produce semantic results (simplification of
tests and information on the essential features of a test) by purely
syntactic means.  This is possible due to TSTL's conversion of testing
into a graph exploration problem, where a test generation algorithm
can be agnostic as to the underlying SUT, or even the language of the
system under test.  The current TSTL implementation is in
Python\footnote{There is also a Java version in alpha.}, but the
normalization and generalization algorithms do not depend on the
underlying language, only on the TSTL-level notions of actions and pools.