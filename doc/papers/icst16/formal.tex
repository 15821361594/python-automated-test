\section{Formal Definitions of Normalization and Generalization}

\subsection{A Brief Introduction to TSTL}

\begin{figure}
{\scriptsize
\begin{code}
@import avl
\vspace{0.1in}
pool: <int> 4 CONST
pool: <avl> 3
\vspace{0.1in}
property: <avl>.check\_balanced()
\vspace{0.1in}
<int> := <[1..20]>
<avl> := avl.AVLTree()
\vspace{0.1in}
<avl>.insert(<int>)
<avl>.delete(<int>)
<avl>.find(<int>)
<avl>.inorder()
\end{code}
}
\caption{Part of a TSTL definition of AVL tree tests}
\label{fig:example}
\end{figure}

\comment{
\begin{figure}
{\scriptsize
\begin{code}
avl1 = avl.AVLTree()  
int3 = 10  
int1 = 11  
avl1.insert(int1) 
int1 = 1  
avl1.insert(int3) 
avl1.insert(int1) 
int3 = 9  
avl1.insert(int3) 
int2 = 11  
avl1.delete(int2) 
\end{code}
}
\caption{An example TSTL-produced test}
\label{fig:avlrun}
\end{figure}
}

TSTL \cite{NFM15,ISSTA15} is a language for defining the structure of
test cases, and a set of tools for use in generating, manipulating,
and understanding those test cases.  Figure \ref{fig:example} shows a
simplified portion of a TSTL definition of tests of an AVL tree class,
in the latest syntax for TSTL (which differs slightly from that in the
cited papers introducing TSTL).  TSTL provides numerous features not
shown in this small example, including automatic differential testing,
complex logging, support for complex guards, and use of pre- and post-
values.  Given a harness like the one in Figure \ref{fig:example},
TSTL compiles it into a class file defining an interface for testing
that provides features such as querying the set of available testing
actions, restarting a test, replaying a test, collecting code coverage
data, and so forth.  The TSTL release
(\url{https://github.com/agroce/tstl}) also provides some testing
tools that make use of this interface to generate tests and provide
other debugging capabilities.

The key point for our purposes is merely that a TSTL test harness
defines a set of \emph{pools} that hold values produced and used
during testing \cite{AndrewsTR} (a common approach to defining
API-testing sequences) and a set of actions that are possible during
testing, typically API calls and assignments to pool values.  In this
example, there are two pools, one named {\tt int} and one named {\tt
  avl}.  There are four instances of the {\tt int} pool, which means
that a test in progress can store up to 4 {\tt int}s at one time (in
variables named {\tt int0}, {\tt int1}, {\tt int2}, and {\tt int3}), and three
instances of the {\tt avl} pool.  The actions defined here are setting
the value of an {\tt int} pool to any integer in the range 1-20
inclusive, setting the value of an {\tt avl} pool to a newly
constructed AVL tree, and calling an AVL tree's {\tt insert}, {\tt
  delete}, {\tt find} and {\tt inorder} methods.  Figure
\ref{threetests} in the introduction shows three
valid test cases produced by running a random test generator on
the TSTL-compiled interface produced by this definition.  TSTL handles
ensuring that tests are well-formed: for example, no pool instance
(such as {\tt avl1} can appear in an action until it has been assigned
a value), and no pool instance that has been assigned a value can be
assigned a different value until it has been used in an action, to
avoid degenerate sequences such as {\tt int3 = 10} followed by {\tt
  int3 = 4}.  Each action in a test case is called a ``step'' --- the
first step of the first test case in Figure \ref{threetests} is storing a new AVL tree in {\tt
  avl0}, for example.

The definition of pools and actions in TSTL defines a \emph{total
  order} on all actions.  First, actions are ordered by their position
in the definition file.  All {\tt insert} actions are therefore before
all {\tt delete} actions, and all {\tt delete} actions are before find
actions.  Of course, one line of TSTL defines many actions, because of
the choices for pools.  For example, the line {\tt
  <avl>.insert(<int>)} defines 12 actions, one for each choice of {\tt
  avl} and {\tt int} pool instance.  These are ordered lexically, in
the obvious way ({\tt avl0} preceeds {\tt avl1}, etc.).  Value ranges
such as in the {\tt int} initialization, are also ordered in the
natural way, with lower values first.  Given this total order, each
action can be assigned a unique index, from 0 up to 1 less than the
total number of actions. Initially, this ordering (and
numbering) for each action was intended to allow for a kind of
Goedel-numbering of tests, for proving certain mathematical properties
\cite{AndrewsTR}.  However, it also allows us to concisely define a
practical method for normalizing and generalizing test cases.

One note: in normal TSTL semantics, the action sequence that assigns a
value to the same pool twice in a row is not allowed --- until a pool
value is used, it cannot be assigned to again.  However, during
normalization and generalization, this restriction is removed.  The
restriction exists only to prevent the generation of un-interesting
test sequences.  The normalization and generalization algorithms avoid
such sequences by other means, and allowing over-writing assignments
makes normalization much more effective.  Such sequences only appear
in intermediate steps; after normalization, test
cases are guaranteed to not have any remaining sequences invalid in
normal TSTL semantics.

\subsection{Normalization}

A test-case normalization algorithm has a simple goal:  we ideally aim to
produce a function $f : t \rightarrow t$ (a function that takes a test
case and returns a test case) such that:

\begin{enumerate}
\item If $t$ fails, $f(t)$ fails.
\item If $t$ and $t'$ fail due to the same fault, $f(t) = f(t')$.
\item If $t$ and $t'$ fail due to different faults, $f(t) \not=
  f(t')$.
\end{enumerate}

Such a function would define a true \emph{canonical form} for test cases, where
each underlying fault is uniquely represented by a single test case.
In general, it seems clear that defining such an $f$ is (at least) as
difficult as automatic fault localization and repair.  Therefore, we
aim at approximating the goal, by providing a set of simple
transformations such that $f$ changes many tests to the same test, $f$
has
low probability of changing two tests failing for different reasons
into the same test, and $f$ is not unreasonably expensive to compute.
The implementation for $f$ (in fact, for a family of $f$-approximating
functions, with different tradeoffs in runtime and level of
normalization) involves defining a set of rewrite rules such that for a
test $b$ (the base test), the rules define a finite set of candidate
tests $c \in C(b)$, possible simplifications of $b$, where each $c$ is
the result of applying some rewrite, $r_i$ to $b$.  The notion of
simplicity is defined by a restriction on the rewriting rules.  For
any test case $t$, let $R(t)$ be the length of the maximum number of
rewrites that can be applied to $t$, e.g., the longest possible
sequence such that $c_0 = r_{i1}(t), c_1 = r_{i2}(c_0), ... c_n = r_{in}(c_{n-1})$. We
require that $\forall c \in C(b), R(c) < R(b)$.  The number of possible
rewrites for each candidate must be smaller than the number of
possible rewrites for $b$.  This implies further restrictons, e.g., no
rewrite can ever reverse another rewrite's effects.  Such a rewrite
system is \emph{strongly normalizing}:  any sequence of rewrites
chosen will eventually end in a term (test case) that cannot be
further rewritten.

In the setting of TSTL, where test actions have a defined total
order, a simple principle can be applied to produce strongly
normalizing rewrite rules: rewrites should reduce the sum of the
indices of the actions in the test case, or make the test case's
actions more ordered by index.  This approach
provides effective normalization at a significant, but not
impractical, computational cost.

The second principle that determines the rewrite rules is that each
rule should be unlikely to change the underlying cause for test case
failure.  To that end, the rules below always either change at most
one action (possibly in multiple steps, but in a uniform way) or make
\emph{no} changes to the actions performed, only to the pools used or the
positions of actions in the test case.  We cannot guarantee
normalization does not change the underlying fault in a test; however,
the limited scope of rewrites should at least make the likelyhood of
fault change (known as ``slippage'' \cite{PLDI13}) around that of
delta-debugging, which is widely accepted as a reasonable tradeoff.

\subsubsection{Definitions and Notation}

In order to formally define normalization, some additional notation is required.
A \emph{step} is an action paired with an index indicating its
position in a test case,
where the first action is step 0, etc.; e.g., $(2: a)$ indicates the
third step of the test is action $a$ (indexing is from 0). 
$\Delta(t,t')$ is the set of all steps in $t$ such that $t(i) \not= t'(i)$.

We use the $<$ operator over various types:
$a < b$ iff the index of action $a$ is lower
than that of action $b$.  We compare steps with $<$ by comparing their
actions --- $(i,a) < (j,b)$ iff $a < b$.  For a set or sequence of actions or steps, we define the $min$ of the
set to be the lowest indexed action in the set, and use
these to compare sets:  $s_1 < s_2$ iff $min(s_1) < min(s_2)$. For pools,
$p < p'$ if and only if $p$'s index is lower than the index for $p'$
\emph{and} $p$ and $p'$ are from the same pool.

The rewrite $t[x \Rightarrow y]$ denotes the test t with all instances of $x$
replaced by $y$.  Here, $x$ and $y$ can be actions, steps, or pools.
$t[x \Leftrightarrow y]$ is similar, except that $x$ and $y$ are
swapped.  Rewrite $t(i,j)[x \Rightarrow y]$ is the same as $t[x \Rightarrow
y]$, except that the replacement is only applied between steps $i$ and
$j$, inclusive.  Finally, $t_i(x)$ denotes $t$ with all steps
containing $x$ that are before step $i$ moved to step $i$, preserving
their previous order, and moving steps at $i$ and after $i$ to make room.

\subsubsection{Rewrite Rules}

\begin{enumerate}
\item {\bf SimplifyAll:}
$c = b[a \Rightarrow a']$\\
\-\ \ \ \emph{where} $a' < a$\\
Covers the case where all appearances of an action can be replaced with a 
simpler (lower-indexed) action. 
\item {\bf ReplacePool:}
$c = b(i,j)[p \Rightarrow p']$\\ 
\-\ \ \ \emph{where} $p < p'$ and $0 \leq i < j <
|b|$\\
Covers the case when all appearances of an instance of a pool can be replaced with 
a lower-indexed instance of that pool (with possible restriction to a range of steps).
\item {\bf ReplaceMovePool:}
$c = b_{\rightarrow i}(p')[p \Rightarrow p']$\\
\-\ \ \ \emph{where} $p < p'$ and $0
\leq i < |b|$\\
Covers the case when all appearances of an instance of a pool can be replaced with
a lower-indexed instance of that pool, if all assignments to the new instance before a
certain step are moved to that step.
\item {\bf SimplifySingle:}
$c = b[(i: a) \Rightarrow (i: a')]$\\
\-\ \ \ \emph{where} $a' < a$\\
Covers the case where one action can be replaced with a 
simpler (lower-indexed) action. 
\item {\bf SwapPool:}
$c = b(i,j)[p \Leftrightarrow p']$\\
\-\ \ \ \emph{where} $\Delta(c,b) < \Delta(b,c)$\\
\-\ \ \ and $0 \leq i < j < |b|$\\
\-\ \ \ and $p < p'$\\
Covers the case where swapping two pool instances (within a range of steps) reduces
the minimal action index of the modified steps.
\item {\bf SwapAction:}
$c = b[(i: a) \Rightarrow (i: b), (j: b) \Rightarrow (j: a)]$\\
\-\ \ \ \emph{where} $i < j$ and
$b < a$\\
Covers the case where two actions can be swapped in the test, with the
lower-indexed action now appearing earlier.
\item {\bf ReduceAction:}
$c = b[(i: a) \Rightarrow (i: a')]$\\
\-\ \ \ \emph{where} $|ddmin(c)| < |ddmin(b)|$\\
Covers the case where an action can be replaced by any action (not just lower-indexed
actions) and this enables further delta-debugging-based reduction of
the test case's length.
\end{enumerate}

\subsubsection{Normalization Algorithm}

These rules alone do not determine a complete normalization method; it is
also required to determine an order in which they are applied.  The
order in our default implementation is the order above, with the
modification that in practice the {\bf ReplacePool} and {\bf
  ReplaceMovePool} rewrites are both performed at once, interleaved
(e.g., for every possible replacement of a pool, both rules are
checked, in the order given above).  The core algorithm, given a set
of ordered rewrite rules defining $C(b)$ is given as Algorithm
\ref{simpalg}.  Here {\tt pred} is an arbitrary predicate indicating
that the candidate test still satisfies the property of interest that
held for the original test $b$.  In most cases, this predicate will be
``the test fails'' but we also have preserved
code coverage for regression suites \cite{icst2014}.  Notice that
after applying each rewrite rule, we perform delta-debugging on the
new base test case, since often a rewrite makes other steps irrelevant.

\begin{algorithm}
\caption{Basic algorithm for normalization}
\label{simpalg}
\begin{algorithmic}[1]
\State {modified = True}
\While {modified}
\State {modified = False}
\For {$c \in C(b)$}
\If{pred($c$)}
\State modified = True 
\State $b$ = $ddmin(c)$
\State {\bf break} (exit {\bf for} loop) 
\EndIf 
\EndFor 
\EndWhile 
\State return $b$
\end{algorithmic}
\end{algorithm}

Assume there are $k$ steps in the test case and $n$ possible actions.
We approximate the complexity of normalization by first bounding the cost for each pass through the
inner {\bf for} loop.  The action replacements and pool movement
replacement rewrites (1, 3, 4, and 7) all require at most $k (n-1)$
predicate checks when no simplification takes place, and all checks
fail.  The {\bf SwapAction} rewrite can obviously require no more than
$k^2$ checks, and the {\bf ReplacePool} rewrite fewer than
$k^2 (n-1)$\footnote{The details of how these bounds are determined,
  in that pool changes are also action changes, are not critical, and
  a more detailed analysis is somewhat involved, and beyond the scope
  of this paper; we note that like delta-debugging, the worst-case
  complexity is seldom observed, and offer some further optimizations
  below.}.  Therefore each inner loop run requires at most
$k^2 + k^2(n-1) + 4k(n-1)$ checks (we assume a constant cost to run a
check --- unlike in delta-debugging, this is a reasonable assumption, as few
rules change the length of the test).  Each time the inner loop finds
a valid rewrite, there is also the cost of a delta-debugging step,
which is at worst quadratic in $k$ \cite{DD}.  The cost of the inner
loop is therefore $O(k^2n)$.  How many times can this inner loop run
(e.g., how many times can the {\bf while} loop run)?  Each
action can be replaced fewer than $n$ times, since each
replacement (or at least one replacement in each rewrite,
for the pool changes) must decrease the index of the action.  Steps
can be swapped fewer than $k$ times, obviously.  Each  {\bf
  ReduceAction} rewrite requires reducing the length of the
test, giving it a total (not per-step, like the other bounds) bound of
$k$ successful rewrites.  This gives us an upper bound of $kn +
k^2 + k$ executions for the outer loop, and a total runtime that is
$O(k^4n)$.

In practice, most actions are not enabled at most steps, and
the rules are applied in an order that quickly converges on a normal
form for many test cases.  In our experiments, normalization is only
very expensive when delta-debugging is also costly, and appears to be
worse than delta-debugging by a constant factor, somewhere in the
range of 2-10x, usually closer to 10x.  We believe that if
normalization can decrease human effort in examining large numbers of
redundant test cases, this price is more than reasonable.  Measuring
the payoff from improved understanding of test cases is difficult;
however, in multiple fault settings, we hope normalization can often
provide a quantifiable value in shorter time until all faults have
been examined by a human, for bug triage \cite{PLDI13}.

\subsubsection{Normalization Optimizations}

The simplest and most important optimization is to improve on the
constant ordering of rewrite rules.  In our implementation, once a
rule fails to produce a candidate that satisfies {\tt pred} that rule
is moved to the end of the ordering of rewrites.  This optimization
followed the observation that almost always once a rule fails to
produce any changes in a test case, it never applies again.  This
simple change, in our experience, typically halves the time required
for normalization.

For test cases with a very short runtime, this algorithm (with
reordering) is usually practical: though more expensive than delta-debugging
it still requires  less than a minute to run.  However, when test case
execution is expensive, the set of candidate test cases must be
further restricted.  In our experiments, we found that restricting
action replacements to cases where the Levenshtein \cite{Lev} distance
(text edit distance) between the code for the actions was bounded was effective in reducing runtime, while almost always having no
impact on the final result.  In practice, most test actions can only
be replaced by syntactically similar actions, without completely
changing test semantics.

A further useful optimization when normalizing large numbers of tests
of the same SUT is to cache results, so that as soon as the rewrite
sequence produces a previously seen test, the final result can be
returned (since the algorithm is deterministic).   For very large
numbers of tests, this is the most important optimization.
Interestingly, though it is also deterministic, caching
delta-debugging results is almost useless, since the chance of seeing
an exact match is very small; this is true with the initial input to
normalization, but a few pool and value changes often result in a
cache hit. For systems with
very expensive replay, the delta-debugging of each new base test case
can also be omitted, as we can count on the {\bf ReduceAction} rewrite to
eventually remove useless steps (however, this may come at a cost of
attempts to rewrite steps that could be removed).

Finally, it is easy to parallelize the normalization of a test case by
checking the predicate over multiple candidates at once.  As soon as a
candidate satisfies the predicate, one of two options are available:
either the normalization can proceed with that candidate as the new
base, making the algorithm nondeterministic (in theory; in
practice we suspect the same final result will usually appear), or the
algorithm can wait for all earlier-in-sequence candidates to be
checked, and only proceed when no candidate that would be checked
first in the sequential version of the algorithm is in the work
queue.

\subsection{Generalization}

\subsubsection{Generalization Algorithm}

The core idea of generalization is to use methods similar to those
involved in normalization to provide a user with information about
changeable aspects of a test case.  Some values and orderings of steps
in a test case are \emph{essential} to the failure: when changed, they
cause the test case to no longer fail.  Many others, however, are
\emph{accidental} --- any concrete test case has to choose \emph{some}
values and step ordering (for us, that enforced by the normalization
process) but many such choices are arbitrary, or at least allow
variance, with respect to the cause of failure.  Generalization
performs experiments to distinguish essential and accidental aspects
of a test case, and summarizes the results.  The core algorithm
(Algorithm \ref{genalg}) is simple.

\begin{algorithm}
\caption{Basic algorithm for generalization}
\label{genalg}
\begin{algorithmic}[1]
\State {swap = $\emptyset$}
\State {replace = $\emptyset$}
\For {$(i, a) \in t$}
\For {$a' : a' > a$}:
\If {pred($t[(i,a) \Rightarrow (i,a')]$)}
\State replace = replace $\cup ((i,a),(i,a'))$
\EndIf
\EndFor 
\For{$j : i < j < |t|-1 \wedge (j: b) > (i: a) $}
\If {pred($t[(i: a) \Rightarrow (i: b), (j: b) \Rightarrow (j: a)]$)}
\State swap = swap $\cup ((i,a),(j,b))$
\EndIf
\EndFor
\EndFor
\State {return (swap, replace)}
\end{algorithmic}
\end{algorithm}

This algorithm collects all steps that can be replaced with other
actions or swapped with other steps, and returns the set to be
reported to the user.  This version assumes the test has already been
normalized, but can be extended to any test case by removing the
restrictions that $a > a'$ and $(j : b) > (i : a)$.  The complexity of
generalization is simpler to determine than that of normalization: if
we assume all actions are enabled at each step, and there are $n$
actions and $k$ steps, checking for replacements requires $k (n-1)$
test case executions (when every action is the lowest-indexed action).
In that worst case, no swaps are possible.  The complexity of checking
for swaps in the worst case is quadratic in $k$.  In practice, most
actions are not enabled at most steps, and most actions in a test case
are not the lowest-indexed action.  Basic generalization is trivial to
parallelize, as all checks are independent.


\subsubsection{Fresh Values and Misleading Test Cases}

A side-effect of delta-debugging and of normalization is the reduction
of the number of variables used in a test case.  While usually helpful
for understanding, this can sometimes result in misleading test
cases.  In stateful system, putting the system into a bad state may require
building a complex object.  Once system state is corrupted, however,
the complex object is irrelevant, and its appearance in the call
leading to failure can be misleading.  In previous work at NASA, we
observed that sometimes a delta-debugged file system test case
\cite{ICSEDiff,AMAI} would use an open file descriptor in a call,
leading to the suspicion that the file had been corrputed, when in
fact the file system's state in memory was damaged, and the same
operation on any file would produce the same problem.  To address this
problem, we present a more aggressive generalization than
replacement and swap:  replacing a pool use with a
fresh value.  

As an example, consider the test case in Figure \ref{fig:mislead},
produced by our TSTL harness that uses TSTL to test TSTL
itself\footnote{Since TSTL provides a Python API, that API can be used
  as the SUT in testing; we have discovered several important TSTL
  bugs this way.}.  The problem involves an invalid normalization
cache, produced by normalizing a test with only one action.  Without
generalization, it appears that the failure comes when this test is
normalized a second time.  However, the information after step 6 shows
that in fact the failure will take place even if an newly created empty test is
normalized.  Without this generalization, the state of the {\tt test} pool
may appear to be important, not the state of the TSTL system itself.

\begin{figure}
{\scriptsize
\begin{code}
\textcolor{black!45}{\#[}
test0 = []                             \textcolor{black!45}{\# STEP 0}
\textcolor{black!45}{\#  or test0 = sut0.test() }
actionlist0 = sut0.actions()           \textcolor{black!45}{\# STEP 1}
\textcolor{black!45}{\#  or actionlist0 = sut0.enabled() }
\textcolor{black!45}{\#] (steps in [] can be in any order)}
action0 = actionlist0[0]               \textcolor{black!45}{\# STEP 2}
\textcolor{black!45}{\#[}
test0.append(action0)                  \textcolor{black!45}{\# STEP 3}
pred0 = sut0.fails                     \textcolor{black!45}{\# STEP 4}
\textcolor{black!45}{\#] (steps in [] can be in any order)}
sut0.normalize(test0,pred0)            \textcolor{black!45}{\# STEP 5}
sut0.normalize(test0,pred0)            \textcolor{black!45}{\# STEP 6}
\textcolor{black!45}{\#  or (}
\textcolor{black!45}{\#      test0 = []  ;}
\textcolor{black!45}{\#      sut0.normalize(test0,pred0) }
\textcolor{black!45}{\#     )}
\end{code}
}
\caption{Generalized test for TSTL itself, showing fresh-object
  generalization.}
\label{fig:mislead}
\end{figure}

Formalizing this generalization requires some additional notation.
$U(a)$ provides a list of pools \emph{used} in the action $a$ --- pools that
appear in the action, not on the left-hand side of an assignment.
$I(a,p)$ is a predicate that is true iff action $a$ stores a new value
in pool $p$.  Finally, $t[+(a: i)]$ denotes test $t$ with the action
$a$ inserted at step $i$ and each step from $i$ onwards moved to a
position one higher.

\begin{algorithm}
\caption{Basic algorithm for fresh object generalization}
\label{freshalg}
\begin{algorithmic}[1]
\State {fresh = $\emptyset$}
\For {$(i, a) \in t$}
\For{$p \in U(a)$}
\For{$a' : I(a',p)$}
\If {pred($t[+(a',i)]$)}
\State fresh = fresh $\cup (i,a')$
\EndIf
\EndFor 
\EndFor
\EndFor
\State {return fresh}
\end{algorithmic}
\end{algorithm}

In practice, the {\tt fresh} set returned should be pruned to avoid
redundant actions.  It is not useful information that the sequence {\tt
  int0 = 1 ; int1 = 2; int0 = 1; f(int0)} fails if {\tt int0 = 1; int1
  = 2; f(int0)} fails.  Redundancy elimination also needs to take into
account the potential assignments to a pool from the {\tt replace}
generalization, which are also redundant.  Furthermore, it is useful
to distinguish between pools that are never modified, only assigned
to, and pools that are modified without appearing on a left-hand
side.  As an example, if an integer is used as an argument to a
function, the pool value's last assignment is still valid and should
be omitted from ``fresh'' values, as redundant.  However, calling a
function on an AVL tree or a list may modify the object, making an
assignment non-redundant, even if it is the last apperance of that
pool on the lhs.  Further extensions of the fresh value generalization
could be considered; e.g., if a fresh value for some object requires use
of a complex constructor, the values required to call the constructor
could also be produced, if they do not appear in the test case
previously (if only one of a set of constructors can produce a fresh
value that will satisfy the predicate).  However, in our experiments
so far, simple fresh value generation suffices, since the needed
inputs to constructors are usually available in pools, and it is not
important to know \emph{all} constructor inputs that could result in a
successful fresh value generalization.

\subsection{Discussion}

The key feature of normalization and generalization as presented in
this paper is that they produce semantic results (simplification of
test cases and information on the essential and accidental features of
a test case) by purely syntactic means.  This is possible due to
TSTL's conversion of testing into a graph exploration problem
\cite{NFM15}, where a test generation algorithm can be agnostic as to
the underlying SUT, or even the language of the system under test.
The current TSTL implementation is in Python\footnote{There is also a
  Java version in beta, with a simpler version of normalization
  implemented.}, but the normalization and generalization algorithms
do not depend on the underlying language, only on the TSTL-level
notions of actions and pools.
